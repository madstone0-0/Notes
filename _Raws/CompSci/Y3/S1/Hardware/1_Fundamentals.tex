\documentclass[12pt letter]{report}
\input{./template/preamble}
\input{./template/macros}
\input{./template/letterfonts}

\title{\Huge{Fundamentals of Computer Architecture}}
\author{\huge{Madiba Hudson-Quansah}}
\date{}
\usepackage{parskip}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

\begin{document}
\maketitle
\newpage
\pdfbookmark[section]{\contentsname}{too}
\tableofcontents
\pagebreak

\chapter{Terminology}

\section{Computer Hardware}

\dfn{Hardware}{
  The physical components of a computer system that can be seen and touched.
}

\begin{itemize}
  \item Central Processing Unit (CPU) - Instruction sets and execution.
  \item Memory - RAM / ROM, caching mechanisms and memory hierarchy.
  \item Input / Output (IO)- Peripherals, buses and device controllers.
  \item Motherboards and Chipsets - Physical layout and connectivity of components.
\end{itemize}

\section{Key Characteristics of Hardware}

\begin{itemize}
  \item Physical Components - Physical parts of a computer system.
  \item Electronic Circuits - Electrical circuits that perform functions such as processing data, storing information
        and facilitating communication between other components.
  \item Peripheral Devices - Devices that are connected to the computer system to provide additional functionality.
  \item Physical Infrastructure - Servers, routers, switches.
  \item Assembly of Components - The physical assembly of components to form a functional computer system.
  \item Firmware - Software that is embedded in hardware components for low level control of the specific component.
  \item Mechanical Parts - Physical parts of a computer system that are not electronic.
\end{itemize}

\section{Operating System Fundamentals}

\dfn{Process}{
  An instance of a program running on a computer system. A process differs from a process by having its own memory space
  and CPU time, i.e. A program becomes a process when it is loaded into memory and executed by the CPU.
}

\begin{itemize}
  \item Process Management - Processing handling - Scheduling, Multitasking, Threads.
  \item Memory Management - Virtual Memory, Paging, Segmentation.
  \item File Systems (FS) - How data is stored, accessed, and organized on ROM.
  \item I/O Management - Managing data transfer between peripherals and the CPU.
  \item Security - Authentication, Authorization, Encryption, and Firewalls.
\end{itemize}

\subsection{Execution of Programs}

Program execution from source files goes through  the following steps:
\begin{enumerate}
  \item Compilation - Source code is compiled into machine code or an intermediate language.
  \item Linking - Libraries and dependencies are linked to the executable file.
  \item Loading - The executable file is loaded into memory by a loader software and executed by the CPU.
  \item CPU Time - The CPU scheduler allocates CPU time to the process for execution.
  \item Process Running - The process is executed by the CPU and performs the required operations.
  \item Process Termination - The process is terminated and the resources are released.
\end{enumerate}

\section{System Architecture}

\begin{itemize}
  \item Von Neumann Architecture - CPU, Memory, IO, and Bus.
  \item Harvard Architecture - Separate memory for data and instructions.
  \item System Buses - Communication between different components of the system, PCI, USB.
  \item Interrupts and Handling - Managing interrupts from hardware devices for processing.
\end{itemize}

\subsection{Von Neumann Architecture}

\dfn{Von Neumann Architecture}{
  A computer architecture that is based on the concept of a stored-program computer. The Von Neumann architecture
  consists of a CPU, Memory, IO, and a Bus. The CPU fetches instructions from memory, decodes them, and executes them
  and then fetches the data the instructions operate on from the same memory usually at another memory address/location.
  The Von Neumann architecture is used in most modern computers.
}

\subsection{Harvard Architecture}
\dfn{Harvard Architecture}{
  A computer architecture that has separate memory for data and instructions. The Harvard architecture allows the CPU to
  fetch data and instructions simultaneously, which can improve performance. The Harvard architecture is used in some
  embedded systems and microcontrollers.
}


\section{Components of a Computer System}

\dfn{System}{
  A collection of components that work together to perform complex computational tasks, manage resources, or provide
  specific services. These components are interconnected and interdependent on each other.
}

\begin{itemize}
  \item CPU - Data Path and Control Unit
        \begin{description}
          \item[Data Path] - Arithmetic and Logic Unit (ALU), Registers, and Cache.
          \item[Control Unit] - Instruction Fetch, Decode, and Execute. Controls the flow of electrons / data to perform
                operations in the CPU.
        \end{description}
  \item Memory - Speed Size trade-off. The faster the memory the smaller the size. Memory hierarchy.
        \begin{enumerate}
          \item Registers - Fastest memory, used to store data that is currently being processed.
          \item Cache - Faster than RAM, used to store frequently accessed data. L1, L2, L3.
          \item RAM - Random Access Memory, used to store data that is currently being processed.
          \item ROM - Read Only Memory, used to store firmware and boot instructions.
                \begin{itemize}
                  \item SSD - Solid State Drive, faster than HDD, used to store data.
                  \item HDD - Hard Disk Drive, slower than SSD, used to store data.
                  \item Optical Drives - CD, DVD, Blu-ray, used to store data.
                  \item Magnetic Tapes - Used for long term storage of data / Archival.
                \end{itemize}
        \end{enumerate}
  \item Input / Output
\end{itemize}

\section{Assembly Language}

\dfn{Assembly}{
  A low-level programming language that is used to write programs that are executed by the CPU. Assembly language is
  specific to the CPU architecture and provides a way to directly control the hardware components of the system. Maps
  mnemonics to machine code instructions. Example \lstinline{ADD}, \lstinline{MOV}, \lstinline{JUMP}
}

Assembly language is less productive than high-level languages but provides more control over the hardware components of
the system. Assembly language programs are translated into machine code by an assembler and executed by the CPU.

\section{General Terminology}

\dfn{Transistor}{
  The fundamental building block of modern electronic devices, acting as a switch for electrical signals.
}

\dfn{Latency}{
  The speed at which memory can be accessed. The time taken for a CPU to access memory.
}

\dfn{Throughput}{
  The amount of data that can be processed in a given amount of time. The number of instructions that can be executed per
  second.
}

\dfn{Cache Hit Ratio}{
  The percentage of memory accesses that are found in the cache. A high cache hit ratio indicates that the cache is
  effectively storing frequently accessed data.
}

\dfn{RISC}{
  Reduced Instruction Set Computer. A computer architecture that uses a small set of simple instructions that can be executed
  quickly. RISC architectures are designed to be efficient and fast by simplifying the instruction set and reducing the
  complexity of the CPU.
}

\dfn{ARM}{
  Advanced RISC Machine. A family of RISC architectures that are widely used in embedded systems, smartphones, tablets,
  and other devices. ARM processors are known for their low power consumption and high performance.
}

\thm{Moore's Law}{\label{moore}
  The number of transistors on a microchip doubles approximately every two years, resulting in an exponential increase in
  computing power. Moore's Law has been a driving force behind the rapid advancement of computer technology.
}

\thm{Amdahl's Law}{\label{amdahl}
  Amdahl's Law is a formula that describes the theoretical speedup of a program when running on multiple processors. The
  formula states that the speedup of a program is limited by the fraction of the program that can be parallelized. Amdahl's
  Law is used to analyse the performance of parallel computing systems.
  \[
    S(n) = \frac{1}{(1 - P) + \frac{P}{n}}
  \]
  Where $S(n)$ is the speedup of the program running on $n$ processors, $P$ is the fraction of the program that can be parallelized.
}

\dfn{Dennard Scaling}{\label{dennard}
  Dennard scaling is a principle that states that as transistors get smaller, their power density remains constant. This
  principle has allowed for the continued increase
}

Improvements in processor performance has slowed down due to the following factors
\begin{itemize}
  \item Transistors no longer getting much better because of the slowing of Moore's Law \ref{moore} and the end of Dennard
        Scaling \ref{dennard}.
  \item The unchanging power budgets for microprocessors.
  \item  The replacement of the single processor with several energy-efficient processors.
  \item The limits to multiprocessing to achieve Amdahl's Law \ref{amdahl}.
\end{itemize}

\chapter{Basic Building Blocks}

\begin{itemize}
  \item Electrons - Negatively charged particles that flow through electrical circuits.
  \item Voltage - The difference in electric potential between two points in an electrical circuit.
  \item Current - The flow of electrons through an electrical circuit.
\end{itemize}

\chapter{Transformation Hierarchy}

\begin{itemize}
  \item Problem
  \item Algorithm
  \item Program /Language
  \item System Software
  \item Software / Hardware Interface
        \begin{itemize}
          \item ISA
                \begin{itemize}
                  \item RISC - Modular relatively simple instructions, energy efficient.
                  \item CISC - Complex instructions, more powerful, less energy efficient.
                \end{itemize}
        \end{itemize}
  \item Micro-architecture
  \item Logic
  \item Devices
  \item Electrons
\end{itemize}

\chapter{Classes of Computers}

Rapid advancements in computer technology have led to the development of different classes of computers that are optimized
for specific tasks and applications. These classes of computers can be broadly categorized into the following categories:
\begin{itemize}
  \item Internet of Things / Embedded Computers
  \item Personal Mobile Devices
  \item Desktop Computing
  \item Servers
  \item Clusters/Warehouse Scale Computers
\end{itemize}

\begin{table}[htpb]
  \centering
  \begin{tabular}{|p{2cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
    \hline
    \textbf{Feature}              & \textbf{Personal Mobile Device}                 & \textbf{Desktop}                      & \textbf{Server}       &
    \textbf{Clusters}             & \textbf{IOT}                                                                                                                   \\ [0.5ex]
    \hline
    \hline
    Price of System               & \$100 - \$1000                                  & \$300 - \$2500                        & \$5000 - \$10,000,000 & \$100,000 -
    \$200,000,000                 & \$10 - \$100,000                                                                                                               \\
    \hline
    Price of Microprocessor       & \$10 - \$100                                    & \$50 - \$500                          & \$200 - \$2000        & \$50 - \$250
                                  & \$0.01 - \$100                                                                                                                 \\
    \hline
    Critical System Design Issues & Cost, energy, media performance, responsiveness & price-performance, energy,
    graphics performance          & Throughput, availability, scalability, energy   & Price-performance, Throughput, energy
    proportionality               & Price, energy, application-specific performance                                                                                \\
    \hline
  \end{tabular}
  \caption{Summary of Classes of Computers}\label{tab:classes}
\end{table}


\section{Internet of Things / Embedded Computers}

\dfn{Embedded Computer}{
  A computer system that is designed to perform a specific task or function. Embedded computers are used in a wide range
  of applications, including consumer electronics, industrial automation, and automotive systems. Embedded computers are
  typically small, low-power devices that are optimized for a specific task.
}

\dfn{Internet of Things (IOT)}{
  Embedded computers that are connected to the internet, typically wirelessly, collecting useful data about their
  environs and interacting with the physical world. Some examples of IOT devices include smart thermostats, smart
  watches, smart cars, and smart homes.
}

Embedded computers have the widest spread of processing power and cost. They include 8-bit to 32-bit processors that may
cost a penny, and high end 64-bit processors for cars and network switches that cost \$100. Price is a key factor in the
design of computers for embedded systems.


\section{Personal Mobile Devices (PMD)}

\dfn{Personal Mobile Device}{
  A small, portable computing device that is designed to be used on the go. Personal mobile devices include smartphones,
  tablets, and wearable devices. These devices are optimized for mobility, battery life, and connectivity.
}

Cost is also a key factor in the design of PMDs, with energy efficiency and media performance also being critical.
Applications of PMDs are often web-based and media oriented. Processors in PMDs are often also considered to embedded
computers because of their low power consumption and small size but are separated due to their ability to run externally
developed software and share many features with desktop computers.

Responsiveness and predictability are key characteristics for media-applications, often requiring real-time performance.
\dfn{Real Time Performance}{
  A segment of an application that has an absolute maximum execution time. For example, in playing a video on a PMD, the
  time to process each frame is limited since the processor must accept and process the next frame shortly.
}
In other applications another requirement arises where the average time for a particular task is constrained as well as
the number of instances when some maximum time is exceeded. This is known as \textbf{Soft Real Time Performance}.

\section{Desktop Computing}

\dfn{Desktop Computer}{
  A personal computer that is designed to be used on a desk or table. Desktop computers are typically larger and more
  powerful than personal mobile devices, with more storage, memory, and processing power. Desktop computers are used for
  a wide range of applications, including gaming, multimedia production, and office work.
}

The desktop market seeks to optimize price-performance chiefly, with energy and graphics performance also being critical.
\dfn{Price-Performance}{
  The combination of performance, measures in terms of compute performance and graphics performance, and the price of
  the computer system.
}

\section{Servers}

\dfn{Server}{
  A computer system that is designed to provide services or resources to other computers on a network. Servers are used
  for a wide range of applications, including web hosting, email, file storage, and database management. Servers are
  typically more powerful than desktop computers and are optimized for throughput, availability, and scalability.
}

The server market is chiefly characterized by the maximization of availability, scalability and throughput.

\subsection{Availability}
\dfn{Availability}{
  The percentage of time that a server is operational and available to provide services. Availability is a critical
  factor for servers that are used in mission-critical applications, such as e-commerce websites and financial systems.
}

\subsection{Scalability}
\dfn{Scalability}{
  The ability of a server system to grow in response to increasing demand for the services they support for an expansion
  in functional requirements.
}
The ability of a server to scale up computing capacity, memory, storage, and the I/O bandwidth is critical for servers that are used in applications that require high performance and reliability.

\subsection{Throughput}
\dfn{Throughput}{
  The overall performance of  a server system, measured in terms of the number of requests it can handle per second or the amount of data it can process in a given time period.
}

\section{Clusters / Warehouse Scale Computers (WSC)}

\dfn{Cluster}{
  A collection of desktop computers or servers connected by local area networks to act as one unified computing
  resource. With each node, a separate computer system, running its own operating system and communicating via a network
  protocol.
}

Price-Performance is also critical to WSCs as they are so large with the majority of the cost of a warehouse associated
with power and cooling the computers inside the warehouse. Availability is also curial for WSCs as the cost for downtime
is very high.

\subsection{WSCs vs Supercomputers}

Supercomputers are designed to optimize floating-point performance and are used for scientific and engineering, running
large communication-intensive batch programs that can run for weeks at a time. WSCs are designed to emphasize
interactive applications, large-scale storage, dependability, and high internet bandwidth.

\chapter{Classes of Parallelism and Parallel Architectures}

\dfn{Parallelism}{
  The ability to perform multiple tasks simultaneously. Parallelism can be achieved at different levels of a computer system, including instruction level, task level, and data level.
}
There are mainly two kinds of parallelism in applications:
\begin{description}
  \item[Data-Level Parallelism (DLP)] - The ability to perform the same operation on multiple data elements simultaneously.
  \item[Task-Level Parallelism (TLP)] - The ability to perform tasks simultaneously and independently.
\end{description}

Computer hardware can be designed to exploit these two kinds of parallelism in four major ways:
\begin{description}
  \item[Instruction Level Parallelism (ILP)] - Exploits DLP with the use of compilers to optimize code to perform tasks
        like pipelining, and speculative execution.
  \item[Vector architectures, graphics processing units (GPUs) and multimedia instruction sets] - Exploits DLP by
        applying a single instruction to a collection of data in parallel.
  \item[Thread-level parallelism ] - Exploits DLP or TLP in a hardware model that allows for interaction between
        parallel threads.
  \item[Request-Level parallelism] - Exploits TLP among largely decoupled tasks specified by the programmer of operating
        system.
\end{description}

With Flynn's Taxonomy, all computers can be classified into categories based on the way they handle parallelism in the
instruction and data streams. The four categories are:
\begin{description}
  \item[Single Instruction, Single Data (SISD)]  - One instruction stream and one data stream are processed at a time. The uni-processor, or a single-core computer. Can perform ILP.
  \item[Single Instruction, Multiple Data (SIMD)] - The same instruction is executed by multiple processors using
        different data steams. SIMD computers exploit DLP by applying the same operations to multiple items of data in
        parallel. Each processor has its own data memory, but there is a single instruction memory and control processor
        that fetches and dispatches instructions.
  \item [Multiple Instruction, Single Data (MISD)] - Multiple processors execute different instructions on the same
        data stream. MISD computers are not common and are not used in practice.
  \item[Multiple Instruction, Multiple Data (MIMD)] - Each processor fetches its own instructions and operates on
        its own data and targets TLP. MIMD computers are more flexible than SIMD computers and can be used for a wider
        range of applications, but is inherently more complex and expensive than SIMD.
\end{description}
This taxonomy is not mutually exclusive, and many computers can be classified into more than one category. For example, a GPU can be classified as both SIMD and MIMD.

\chapter{Defining Computer Architecture}

\section{Instruction Set Architecture}

\dfn{Instruction Set Architecture (ISA)}{
  The boundary between software and hardware. The actual instructions the computer/processor receives to process data
}

\begin{description}
  \item[Class of ISA] - Most modern ISAs are classified as general-purpose register architectures, where operands are
        either registers or memory locations.
  \item[Memory Addressing]- All modern computers use byte addressing to access memory operands, with some architectures
        like ARMv8, requiring objects to me aligned. An access to an object of size $s$ bytes at byte address $A$ is aligned
        if $A \mod s = 0$, alignment allows for generally faster accessing.
  \item[Addressing Modes] - In addition to specifying registers and constant operands addressing modes specify the
        address of a memory object. For example RISC-V have addressing modes including Register, Immediate,
        Displacement.
  \item[Types and size of operands]- Most ISAs support operand sizes of 8-bit (ASCII characters), 16-bit (Unicode
        character / Half word), 32-bit (integer / word), 64-bit (long integer/double word), IEEE 754 floating point
        32-bit (single precision), and 64-bit (double precision).
  \item[Operations] -
\end{description}

\chapter{Energy Efficiency and Systems Architecture}

\dfn{System Architecture}{
  The way in which the components of a computer system are organized and connected. System architecture includes the design
  of the CPU, memory, IO, and bus, as well as the way in which these components interact with each other.
}

\section{Energy Efficiency}

\dfn{Energy Efficiency}{
  The ability of a computer system to perform tasks using the least amount of energy possible. Energy efficiency is
  important for reducing the environmental impact of computing and lowering the cost of operating computer systems.
}
(DVFS)
\dfn{Performance}{
  The speed at which a computer system can perform tasks. Performance is typically measured in terms of the number of
  instructions executed per second or the amount of data processed per second.
  \[
    \text{Performance} = \frac{1}{\text{Execution Time}}
  \]
}

\subsection{Metrics}

\nparagraph{Power Usage Effectiveness (PUE)}
\dfn{Power Usage Effectiveness (PUE)}{
  Used to evaluate the energy efficiency of a data centre. The ratio of the total facility power to the power used by the equipment in a data centre. PUE is used to measure the
  energy efficiency of a data centre, with lower values indicating higher efficiency. Always greater than 1.
  \[
    \text{PUE} = \frac{\text{Total Facility Power}}{\text{IT Equipment Power}}
  \]
}

\nparagraph{Green Energy Usage}
\dfn{Green Energy Usage}{
  The percentage of energy consumed by a computer system that comes from renewable sources, such as solar, wind, or
  hydroelectric power. Reflects the system's environmental sustainability.
}

\nparagraph{Performance Per Watt (PPW)}
\dfn{Performance Per Watt (PPW)}{
  The amount of performance that can be achieved per watt of power consumed. PPU is used to measure the energy efficiency
  of a computer system, with higher values indicating higher efficiency.
  \[
    \text{PPW} = \frac{\text{Computational performance}}{\text{Power Consumed}}
  \]
}

\nparagraph{Energy Star Rating}
\dfn{Energy Star Rating}{
  A certification program indicating that a computer or other electronic devices meet specific energy efficiency
  guidelines set by the U.S. Environmental Protection Agency (EPA). Devices with a higher star rating are more energy
  efficient.
}

\nparagraph{Carbon Footprint}
\dfn{Carbon Footprint}{
  The total amount of greenhouse gas emissions, measured in Carbon Dioxide equivalents ( $CO_2$ ), produced directly or
  indirectly by a computer system.
}

\nparagraph{Dynamic Voltage and Frequency Scaling (DVFS)}
\dfn{Dynamic Voltage and Frequency Scaling }{
  Allows for the adjustment of a system's voltage and frequency based on workload requirements. Measures how effectively
  a system can scale its power consumption in response to varying workloads.
}

\nparagraph{Idle Power Consumption}
\dfn{Idle Power Consumption}{
  The power consumption of a computer system when it is in an idle or low-activity state. Low idle power consumption is
  vital especially in situations where the system spends significant time in idle states.
}

\nparagraph{Energy Consumption Index (ECI)}
\dfn{Energy Consumption Index}{
  The total energy consumed by a computer system over a specific period of time, often normalized to a standard unit of
  time. Provides a holistic view of the energy consumption of a system and useful in long term sustainability
  assessments.
}

\nparagraph{Energy Efficiency Ratio (EER)}
\dfn{Energy Efficiency Ratio }{
  Measures the energy efficiency of a computer system by comparing the useful work output to the energy input. Commonly
  used in terms of cooling units within data centres.
  \[
    \text{EER} = \frac{\text{Useful Work Output}}{\text{Energy Input}}
  \]
}

\nparagraph{Power Supply Efficiency (PSE)}
\dfn{Power Supply Efficiency (PSE)}{
  Assesses the efficiency of a computer system's power supply unit. The higher the better
  \[
    \text{PSE} = \frac{\text{Output Power}}{\text{Input Power}} \times 100
  \]
}

\nparagraph{Renewable Energy Factor (REF)}
\dfn{Renewable Energy Factor (REF)}{
  Quantifies the proportion of a data centre's energy that comes from renewable sources.
}

\section{Importance of Efficient Designs in Modern Systems}

\begin{description}
  \item[Resource Optimization] - Efficient design minimizes resource usage (CPU, Memory, energy), while maximizing
        performance.
  \item[Cost Saving] - Optimization resource utilization leads to less overall resources being using saving cost and
        increasing the overall return on investment (ROI) for organizations.
  \item[Environmental Impact] - Promotes sustainability by reducing energy consumption and carbon footprint.
  \item[User Experience] - Enhances system responsiveness and reliability leading to a better user experience.
\end{description}

\chapter{Key Design Principles}

\section{Modularity}
\dfn{Modularity}{
  Involves breaking a system down into independent, interchangeable and cohesive parts, with each part performing a
  specific function. This allows for independent development, testing and maintenance of different parts of system
  reducing complexity, i.e. Abstraction of various of the systems various operations.
}

Modularity is important as it allows for enhanced flexibility, scalability, re usability and maintainability of a
system.

\section{Scalability}
\dfn{Scalability}{
  A system's ability to handle an increasing workload by adding resources without significantly affecting performance. A
  well modularized system can be easily scaled by replicating or adding more modules targeting the specific performance
  bottleneck.
}

Scalability ensures that a system can grow and adapt to changing requirements and effectively utilize available
resources as workload increases.

\section{Reliability}
\dfn{Reliability}{
  A measure of a system's ability to perform its intended function consistently and accurately with minimal downtime
  over time. Reliability is achieved through redundancy / backup systems, fault tolerance, and error detection and
  recovery..
}

Reliability is critical for mission-critical systems, such as servers, where downtime can result in significant consequences.

\section{Maintainability}
\dfn{Maintainability}{
  The ease at which a system can be repaired, updated, or modified. A well-designed system is easy to maintain and
  requires minimal effort to fix issues or add new features. Maintainability is achieved through good documentation,
  debugging tools, and modular design.
}

Maintainability reduces downtime, the cost of ownership, and extends the life of a system.

\section{Balancing Trade-offs}

\chapter{Digital Systems}

\section{Introduction}

\dfn{Digital System}{
  A system that processes digital signals, which are discrete, quantized representations of analog signals. Digital
  systems use binary digits (bits) to represent data and perform operations on that data.
}

\subsection{Digital vs. Analog Systems}

\nparagraph{Analog Systems}

Analog systems process analog signals, which are continuous, variable representations of physical quantities. Analog systems
are used in applications where continuous data is required, such as audio and video processing, and control systems.

\nparagraph{Digital Systems}

Digital systems process digital signals, which are discrete, quantized representations of analog signals. Digital systems
are used in applications where discrete data is required, such as computing, communication, and signal processing.

\nparagraph{Digital vs. Analog Signals}

\begin{description}
  \item[Digital Systems] - Process digital signals, which are discrete, quantized representations of analog signals.
  \item[Analog Systems] - Process analog signals, which are continuous, variable representations of physical quantities.
\end{description}

\subsection{Analog to Digital Conversion (ADC)}

\dfn{Sampling}{
  Sampling is the process of converting an analog signal into a digital signal by measuring the value of the analog signal at regular intervals.
}

\dfn{Quantization}{
  Quantization is the process of converting the continuous values of an analog signal into discrete values by rounding
  the measured values to the nearest digital value / The process of converting an analog signal into a digital signal by measuring the value of the analog signal at regular intervals and rounding the measured values to the nearest digital value.
}

To convert an analog signal into a digital signal, the analog signal is sampled at regular intervals, and the measured values are quantized to the nearest digital value. The resulting digital signal is a discrete, quantized representation of the original analog signal.

\subsection{Signal Representation}

\dfn{Logic HIGH}{
  A logic HIGH signal is a logic system where a voltage level higher than 0 volts is considered a 1 and a voltage level
  of 0 volts is considered a 0.
}

\dfn{Logic LOW}{
  A logic LOW signal is a logic system where a voltage level of 0 volts is considered a 1 and a voltage level higher than
  0 volts is considered a 0.
}

Logic LOW is mostly used by euro-centric systems, while Logic HIGH is used by American systems.

\end{document}
