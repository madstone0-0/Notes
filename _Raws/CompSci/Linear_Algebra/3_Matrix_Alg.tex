\documentclass[12pt letter]{report}
\input{./template/preamble}
\input{./template/macros}
\input{./template/letterfonts}

\title{\Huge{Matrix Algebra}}
\author{\huge{Madiba Hudson-Quansah}}
\date{}
\usepackage{parskip}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

\begin{document}
\maketitle
\newpage
\pdfbookmark[section]{\contentsname}{too}
\tableofcontents
\pagebreak

\chapter{Matrix Operations}


If $A$ is a $n \times m$ matrix then the scalar entry in the $i$th row and the $j$th column of $A$ is denoted by
$a_{ij}$, and is called the $ \left( i, j \right) $-entry. Each column of $A$ is a list of $m$ real numbers in the
$\mathbb{R}^{m}$ vector space. Therefore the columns of $A$ can be represented as vectors in $\mathbb{R}^{m}$:
\[
  A = \begin{bmatrix} \mbold{a}_1 & \mbold{a}_2 & \ldots \mbold{a}_n \end{bmatrix}
\]

\dfn{Diagonals}{
  The diagonal entries of a matrix $A$ of dimension $n \times m$, are the entries $a_{ij}$, where $i = j$. This is
  called the \textbf{main diagonal} of the matrix $A$. A \textbf{diagonal matrix} is a square matrix $n\times n$ whose
  non-diagonal entries are all zero.
}

\section{Sums and Scalar Multiples}

\dfn{Equality of Matrices}{
  Two matrices $A$ and $B$, are equal if:
  \begin{itemize}
    \item The are of the same size i.e, $m\times x$
    \item The corresponding entries are equal i.e, $A_{ij} = B_{ij}$
  \end{itemize}
}

\thm{Axioms of Matrix Addition}{
  Let $A, B$ and $C$ be matrices of the same size, and let $r$ and $s$ be scalars. Then the following axioms hold:
  \begin{description}
    \item[Communtativity] $A + B = B + A$
    \item[Associativity] $ \left( A + B \right) + C = A + \left( B + C\right)  $
    \item[Additive Identity] $A + 0 = A$
    \item[Distruibutivity 1] $r\left( A + B \right) = rA + rB$
    \item[Distruibutivity 2] $ \left( r + s \right) A = rA + sA $
    \item[Compatibility with Scalar Multiplication] $r\left( sA \right) = \left( rs \right)A$
  \end{description}
}

\section{Matrix Multiplication}

When a matrix $B$ multiples a vector $\mbold{x}$, it transforms $\mbold{x}$ into the vector $B\mbold{x}$. If this vector
is then multiples by another matrix $A$, the result is the vector $A \left( B \mbold{x}\right) $. Thus $A \left( B
  \mbold{x}\right) $ is produced by a composition of mappings / linear transformations. This can be also expressed as:
\[
  A \left( B \mbold{x}\right) = \left( AB \right) \mbold{x}
\]

Because, if $A$ is $m\times n$, $B$ is $n\times p$ and $\mbold{x}$ is in $\mathbb{R}^{p}$, can denote the columns of
$B$, by $\mbold{b}_1, \ldots, \mbold{b}_p$ and the entries of $\mbold{x}$ by, $x_1, \ldots, x_p$. Then
\[
  B \mbold{x} = x_1 \mbold{b}_1 + \ldots + x_p \mbold{b}_p
\]
By the linearity of matrix multiplication, we have:
\begin{align*}
  A \left( B \mbold{x} \right) & = A \left( x_1 \mbold{b}_1 \right) + \ldots + A \left( x_p \mbold{b}_p \right) \\
                               & = x_1 \left( A\mbold{b}_1 \right) + \ldots + x_p \left( A \mbold{b}_p \right)  \\
\end{align*}
The vector $A \left( B\mbold{x} \right) $ is then a linear combination of the vectors $A\mbold{b}_1, \ldots,
  A\mbold{b}_p$, using the entries of $\mbold{x}$ as weights. This can be expressed in matrix notation as:
\[
  A \left( B \mbold{x} \right)  = \begin{bmatrix} A \mbold{b}_1 & A \mbold{b}_2 & \ldots & A \mbold{b}_p \end{bmatrix}
  \mbold{x}
\]
\thm{}{
  If $A$ is an $m \times n$ matrix, and if $B$ is an $n \times p$ matrix with columns $\mbold{b}_1, \ldots, \mbold{b}_p$,
  then the product $AB$ is the $m \times p$ matrix whose columns are $A\mbold{b}_1, \ldots, A\mbold{b}_p$.That is:
  \[
    A \left( B \mbold{x} \right)  = \begin{bmatrix} A \mbold{b}_1 & A \mbold{b}_2 & \ldots & A \mbold{b}_p \end{bmatrix}
    \mbold{x}
  \]
}

\ex{}{
  \qs{}{
    Compute $AB$ where $A = \begin{bmatrix} 2 & 3 \\ 1 & -5 \end{bmatrix} $, and $B = \begin{bmatrix} 4  & 3 & 6 \\ 1 &
                -2 & 3\end{bmatrix} $
  }

  \sol{
    \begin{align*}
      A \mbold{b}_1 & = \begin{bmatrix} 2 & 3 \\ 1 & -5 \end{bmatrix} \begin{bmatrix} 4 \\ 1 \end{bmatrix}  \\
                    & = \begin{bmatrix}
                          8 + 3 \\
                          4 + -5
                        \end{bmatrix}                                                                      \\
                    & = \begin{bmatrix}
                          11 \\
                          -1
                        \end{bmatrix}                                                                      \\
      \\
      A \mbold{b}_2 & = \begin{bmatrix} 2 & 3 \\ 1 & -5 \end{bmatrix} \begin{bmatrix} 3 \\ -2 \end{bmatrix} \\
                    & = \begin{bmatrix}
                          6 - 6 \\
                          3 + 10
                        \end{bmatrix}                                                                      \\
                    & = \begin{bmatrix}
                          0 \\
                          13
                        \end{bmatrix}                                                                      \\
      \\
      A \mbold{b}_3 & = \begin{bmatrix} 2 & 3 \\ 1 & -5 \end{bmatrix} \begin{bmatrix} 6 \\ 3 \end{bmatrix}  \\
                    & = \begin{bmatrix}
                          21 \\
                          -9
                        \end{bmatrix}                                                                      \\
      \\
      AB            & =  \begin{bmatrix}
                           11 & 0  & 21 \\
                           -1 & 13 & -9
                         \end{bmatrix}                                                                     \\
    \end{align*}
  }
}

\thm{Row-Column Rule}{
If the product $AB$ is defined, them the entry in row $i$ and column $j$ of $AB$ is the sum of the products of
corresponding entries of the row $i$ of $A$ and column $j$ of $B$. If $ \left( A B \right)_{ij} $ denotes the $ \left(
  i, j \right) $-entry in $A B$, and if $A$ is an $m \times n$, then
\[
  \left( A B \right)_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} + \ldots + a_{in}b_{nj}
\]
}

\ex{}{
  Use the rowâ€“column rule to compute two of the entries in $A B$ for the
  matrices:
  \[
    A = \begin{bmatrix}
      2 & 3  \\
      1 & -5
    \end{bmatrix}, \,
    B = \begin{bmatrix}
      4 & 3  & 6 \\
      1 & -2 & 3
    \end{bmatrix}
  \]
  An inspection of the numbers involved will make it clear how
  the two methods for calculating $A B$ produce the same matrix. \\


  The dimensions of the resultant matrix is $2 \times 3$, therefore the entries of $A B$ are:
  \begin{align*}
    A B & = \begin{bmatrix}
              2 \left( 4 \right)+ 3 \left( 1 \right)  & 2 \left( 3 \right)  + 3 \left( -2 \right) & 2 \left( 6 \right) + 3
              \left( 3 \right)                                                                                             \\
              1 \left( 4 \right)  -5 \left( 1 \right) & 1 \left( 3 \right) - 5 \left( -2 \right)  & 1 \left( 6 \right) - 5
              \left( 3 \right)
            \end{bmatrix} \\
        & = \begin{bmatrix}
              11 & 0  & 21 \\
              -1 & 13 & 9  \\
            \end{bmatrix}                                                                                               \\
  \end{align*}
}

\ex{}{
  \qs{}{
    Find the entries in the second row of $AB$ where,
    \[
      A = \begin{bmatrix}
        2  & -5 & 0  \\
        -1 & 3  & -4 \\
        6  & -8 & -7 \\
        -3 & 0  & 9
      \end{bmatrix}, \,
      B = \begin{bmatrix}
        4 & -6 \\
        7 & 1  \\
        3 & 2
      \end{bmatrix}
    \]
  }

  \sol{
    \begin{align*}
      \begin{bmatrix} -1 & 3 & -4 \end{bmatrix} \begin{bmatrix} 4 & -6 \\ 7 & 1 \\ 3 & 2 \end{bmatrix} \\
      \begin{bmatrix}
        -4 + 21 - 12 & 6 + 3 - 8
      \end{bmatrix}                                                                         \\
      \begin{bmatrix} 5 & 1 \end{bmatrix}
    \end{align*}
  }
}

\thm{Axioms of Matrix Multiplication}{
  Let $A$ be an $m \times n$ matrix and let $B$ and $C$ have sizes for which  the indicated sums and products are
  defined:
  \begin{description}
    \item[Associativity]  $A \left( B C \right) = \left( A B \right)  C$
    \item[Left Distruibutivity] $A \left( B + C \right) = A B + A C $
    \item[Right Distruibutivity] $ \left( B + C \right) A = B A + C A $
    \item[Scalar Associativity] $ r \left( A B \right) = \left( r A \right) B = A \left( r B \right), \, \forall r, \, r
            \in \mathbb{F}$
    \item[Mutliplicative Identitiy] $I_{m}A = A = A I_{n} $
  \end{description}
}

\ex{}{
  \qs{}{
    Let $A = \begin{bmatrix} 5 & 1 \\ 3 & -2 \end{bmatrix} $ and $B = \begin{bmatrix} 2 & 0 \\ 4 & 3 \end{bmatrix} $. Show
    that these matrices do not commute, I.e, verify $A B \neq  B A$
  }

  \sol{
    \begin{align*}
      A B            & = \begin{bmatrix} 5 & 1 \\ 3 & -2 \end{bmatrix} \begin{bmatrix} 2 & 0 \\ 4 & 3 \end{bmatrix} \\
                     & = \begin{bmatrix}
                           14 & 3  \\
                           -2 & -6
                         \end{bmatrix}                                                                             \\
      \\
      B A            & = \begin{bmatrix} 2 & 0 \\ 4 & 3 \end{bmatrix} \begin{bmatrix} 5 & 1 \\ 3 & -2 \end{bmatrix} \\
                     & = \begin{bmatrix}
                           10 & 2  \\
                           29 & -2
                         \end{bmatrix}                                                                             \\
      \\
      \therefore A B & \neq BA
    \end{align*}
  }
}

\subsection{Powers of a Matrix}

\dfn{Powers of a Matrix}{
  If $A$ is an $n \times n$ matrix and if $k$ is a positive integer, then $A^k$ denotes the product of $k$ copies of
  $A$:
  \[
    A^{k} = A_1 \ldots A_k
  \]
  Where $A_1 = A_2 \wedge A_2 = A_3 \wedge \ldots \wedge A_{k-1} = A_k$
}

If $A$ is non-zero and if $\mbold{x}$ is in $\mathbb{R}^{n}$, then $A^{k} \mbold{x}$ is the result of left-multiplying
$\mbold{x}$ by $A$ repeatedly $k$ times.

If $k = 0$, then $A^{0} \mbold{x}$ is $\mbold{x}$. Thus $A^{0}$ is interpreted as the Identity matrix.

\section{The Transpose of a Matrix}

\dfn{The Transpose of a Matrix}{
Given a matrix $A$, its \textit{transpose}, denoted by $A^T$, is defined by transforming  the rows of $A$ into columns.
For example:
\[
  \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6  \end{bmatrix}^{T} = \begin{bmatrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{bmatrix}
\]
Therefore formally, the transpose of a matrix $A_{m,n}$ is defined as:
\[
  A^T_{m,n}  = A_{n,m}
\]
}

Therefore, let $A$ and $B$ denote matrices whose sizes are appropriate for the following sums and products:
\begin{enumerate}
  \item $ \left( A^{T} \right)^{T} = A$
  \item $ \left( A + B \right)^{T} = A^{T} + B^{T} $
  \item $\forall r \in \mathbb{F}, \, \left( r A \right)^{T} = r A^{T}  $
  \item $ \left( A B \right)^{T} = B ^{T} A^{T} $ \label{thm:asctrans}
\end{enumerate}

Usually $ \left( A B \right)^{T} $ is not equal $A ^{T} B^{T}$, even when $A$ and $B$ have dimensions such that $A ^{T}
  B^{T}$ is defined. The generalization of axiom \ref{thm:asctrans} to products more than two factors is as follows:

\thm{}{
  The transpose of a product of matrices equals the product of their transpose in the reverse order.
}

\chapter{The Inverse Of A Matrix}

\section{Invertibility}

\dfn{Invertibility}{
  Let $A = \begin{bmatrix} a & b \\ c & d \end{bmatrix} $. If $ad - bc \neq  0$, then $A$ is invertible and
  \[
    A^{-1} = \frac{1}{ad - bc} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}
  \]
  If $ad - bc = 0$, then $A$ is not invertible. Where $ad-bc$ is known as the \textit{determinant} \label{thg:det} and denoted by
  \[
    \det A  = ad - bc
  \]
}

\thm{}{
  If $A$ is an invertible $n \times n$ matrix, then for each $\mbold{b}$ in $\mathbb{R}^{n}$, the equation $A \mbold{x}
    = \mbold{b}$ has the unique solution:
  \[
    \mbold{x} = A^{-1} \mbold{b}
  \]
}

\thm{}{
  \begin{enumerate}
    \item If $A$ is an invertible matrix, then $A^{-1}$ is invertible and
          \[
            \left( A^{-1} \right)^{-1} = A
          \]
    \item If $A$ and $B$ are $n \times n$ invertible matrices, then so $AB$, and the inverse of $A B$ is the product of
          the inverses of $A$ and $B$ in the reverse order:
          \[
            \left( A B \right) ^{-1} = B^{-1} A^{-1}
          \]
    \item If $A$ is an invertible matrix, then so is $A^{T}$ and the inverse of $A^T$ is the transpose of $A^{-1}$:
          \[
            \left( A^T \right)^{-1} = \left( A^{-1} \right) ^T
          \]

  \end{enumerate}
}

\section{Elementary Matrices}

\dfn{Elementary Matrix}{
  A matrix obtained by performing a single elementary row operation on an identity matrix.
}

\ex{}{
  \qs{}{
    Let
    \[
      E_1 = \begin{bmatrix} 1 & 0 &0 \\0 & 1 & 0 \\ -4 & 0 & 1  \end{bmatrix}, \, E_2 = \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0
                  & 0     \\ 0 & 0 & 1\end{bmatrix}, \, E_3 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 5
      \end{bmatrix}, \, A \begin{bmatrix} a & b & c \\ d & e & f \\ g &h&i \end{bmatrix}
    \]
  }
  Compute $E_1A$, $E_2A$, $E_3A$, and describe how these products can be obtained by elementary row operations on $A$.

  \sol{
    \begin{align*}
      E_1 A & =\begin{bmatrix} 1 & 0 &0 \\0 & 1 & 0 \\ -4 & 0 & 1  \end{bmatrix} \begin{bmatrix} a & b & c \\ d & e & f \\
                g & h & i\end{bmatrix} \\
            & = \begin{bmatrix}
                  a      & b       & c       \\
                  d      & e       & f       \\
                  -4a+ g & -4b + h & -4c + 1
                \end{bmatrix}                                                                              \\
      \\
      E_2 A & = \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0
                  & 0     \\ 0 & 0 & 1\end{bmatrix} \begin{bmatrix} a & b & c \\ d & e & f \\ g &h&i \end{bmatrix}      \\
            & = \begin{bmatrix}
                  d & e & f \\
                  a & b & c \\
                  g & h & i
                \end{bmatrix}                                                                                          \\
      \\
      E_3 A & = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 5
                \end{bmatrix} \begin{bmatrix} a & b & c \\ d & e & f \\ g &h&i \end{bmatrix}                            \\
            & = \begin{bmatrix}
                  a  & b  & c  \\
                  d  & e  & f  \\
                  5g & 5h & 5i
                \end{bmatrix}                                                                                          \\
    \end{align*}
    \begin{itemize}
      \item     $E_1A$ could be obtained by the elementary row operation $-4R_1 + R_3 \to R_3$
      \item $E_2A$ could be obtained by the elementary row operation $R_1 \leftrightarrow R_2$
      \item $E_3A$ could be obtained by the elementary row operation $5R_3 \to R_3$
    \end{itemize}
  }
}


\cor{}{
  If an elementary row operation is performed on an $m \times n$ matrix $A$, the resulting matrix can be expressed as
  $E A$, where $E$ is the $m \times m$ matrix created by performing the same row operation on $I_m$
}

Since row operations are reversible, all elementary matrices are invertible. Therefore there exists an elementary matrix
$F$ such that
\[
  F E = I
\]
And since $E$ and $F$ correspond to reverse operations $EF = I$, also.

\ex{}{
  \qs{}{
    Find the inverse of $E_1 = \begin{bmatrix}
        1  & 0 & 0 \\
        0  & 1 & 0 \\
        -4 & 0 & 1
      \end{bmatrix} $
  }

  \sol{
    To transform this matrix into $I_3$ we must get rid of the $-4$ entry in the third row. This can be done by the row
    operation $4R_1 + R_3 \to R_3$, which corresponds to the elementary matrix:
    \[
      E^{-1}_1 = \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        4 & 0 & 1
      \end{bmatrix}
    \]
    Checking our answer:
    \begin{align*}
      E_1 E^{-1}_1 & = \begin{bmatrix}
                         1  & 0 & 0 \\
                         0  & 1 & 0 \\
                         -4 & 0 & 1
                       \end{bmatrix} \begin{bmatrix}
                                       1 & 0 & 0 \\
                                       0 & 1 & 0 \\
                                       4 & 0 & 1
                                     \end{bmatrix} \\
                   & = \begin{bmatrix}
                         1 & 0 & 0 \\
                         0 & 1 & 0 \\
                         0 & 0 & 1
                       \end{bmatrix}               \\
    \end{align*}
    This is indeed the identity matrix $I_m$

  }
}
\thm{}{
  An $n\times n$ matrix $A$ is invertible if and only if $A$ is row equivalent to $I_n$, and in this case, any sequence
  of elementary row operations that reduces $A$ to $I_n$ also transforms $I_n$ into $A^{-1}$
}

\subsection{Finding $A^{-1}$}

To find the inverse of a matrix $A$, we can augment $A$ with the $n \times n$ identity matrix $I_n$ and then row reduce.
If $A$ is row equivalent to $I_{n}$ then $\begin{bmatrix} A & I \end{bmatrix} $ is row equivalent to $\begin{bmatrix} I
     & A^{-1}\end{bmatrix} $. Otherwise, $A$ does not have an inverse.

\ex{}{
  \qs{}{
    Find the inverse of the matrix $A = \begin{bmatrix}
        0 & 1  & 2 \\
        1 & 0  & 3 \\
        4 & -3 & 8
      \end{bmatrix} $
  }

  \sol{
    \begin{align*}
      \begin{bmatrix} A &I \end{bmatrix}  = \begin{bmatrix}
                                              0 & 1  & 2 & 1 & 0 & 0 \\
                                              1 & 0  & 3 & 0 & 1 & 0 \\
                                              4 & -3 & 8 & 0 & 0 & 1
                                            \end{bmatrix} \\
      R_1 \leftrightarrow R_3                                      \\
      \begin{bmatrix}
        4 & -3 & 8 & 0 & 0 & 1 \\
        1 & 0  & 3 & 0 & 1 & 0 \\
        0 & 1  & 2 & 1 & 0 & 0 \\
      \end{bmatrix}
      \\
      \frac{1}{4}R_1 - R_2  \rightarrow R_2                        \\
      \begin{bmatrix}
        4 & -3           & 8  & 0 & 0  & 1           \\
        0 & \frac{-3}{4} & -1 & 0 & -1 & \frac{1}{4} \\
        0 & 1            & 2  & 1 & 0  & 0           \\
      \end{bmatrix}
      \\
      \frac{-4}{3}R_2 - R_3  \rightarrow R_3                       \\
      \begin{bmatrix}
        4 & -3           & 8            & 0  & 0           & 1            \\
        0 & \frac{-3}{4} & -1           & 0  & -1          & \frac{1}{4}  \\
        0 & 0            & \frac{-2}{3} & -1 & \frac{4}{3} & \frac{-1}{3} \\
      \end{bmatrix}
      \\
      4R_2 - R_1  \rightarrow R_1                                  \\
      \begin{bmatrix}
        -4 & 0            & -12          & 0  & -4          & 0            \\
        0  & \frac{-3}{4} & -1           & 0  & -1          & \frac{1}{4}  \\
        0  & 0            & \frac{-2}{3} & -1 & \frac{4}{3} & \frac{-1}{3} \\
      \end{bmatrix}
      \\
      \frac{3}{2}R_3 - R_2  \rightarrow R_2                        \\
      \begin{bmatrix}
        -4 & 0           & -12          & 0            & -4          & 0            \\
        0  & \frac{3}{4} & 0            & \frac{-3}{2} & 3           & \frac{-3}{4} \\
        0  & 0           & \frac{-2}{3} & -1           & \frac{4}{3} & \frac{-1}{3} \\
      \end{bmatrix}
      \\
      18R_3 - R_1  \rightarrow R_1                                 \\
      \begin{bmatrix}
        4 & 0           & 0            & -18          & 28          & \frac{-6}{1} \\
        0 & \frac{3}{4} & 0            & \frac{-3}{2} & 3           & \frac{-3}{4} \\
        0 & 0           & \frac{-2}{3} & -1           & \frac{4}{3} & \frac{-1}{3} \\
      \end{bmatrix}
      \\
      - R_1  \rightarrow R_1                                       \\
      \begin{bmatrix}
        -4 & 0           & 0            & 18           & -28         & \frac{6}{1}  \\
        0  & \frac{3}{4} & 0            & \frac{-3}{2} & 3           & \frac{-3}{4} \\
        0  & 0           & \frac{-2}{3} & -1           & \frac{4}{3} & \frac{-1}{3} \\
      \end{bmatrix}
      \\
      \frac{-1}{4}R_1 \to R_1                                      \\
      \frac{4}{3}R_2 \to R_2                                       \\
      \frac{-3}{2}R_3 \to R_3                                      \\
      \begin{bmatrix}
        1 & 0 & 0 & \frac{-9}{2} & 7  & \frac{-3}{2} \\
        0 & 1 & 0 & -2           & 4  & -1           \\
        0 & 0 & 1 & \frac{3}{2}  & -2 & \frac{1}{2}  \\
      \end{bmatrix}
      \\
    \end{align*}
    Since $A \sim I$, $A$ is invertible and
    \[
      A^{-1}= \begin{bmatrix}
        \frac{-9}{2} & 7  & \frac{-3}{2} \\
        -2           & 4  & -1           \\
        \frac{3}{2}  & -2 & \frac{1}{2}  \\
      \end{bmatrix}
    \]
    Checking our answer:
    \begin{align*}
      A A^{-1} & = \begin{bmatrix}
                     0 & 1  & 2 \\
                     1 & 0  & 3 \\
                     4 & -3 & 8
                   \end{bmatrix} \begin{bmatrix}
                                   \frac{-9}{2} & 7  & \frac{-3}{2} \\
                                   -2           & 4  & -1           \\
                                   \frac{3}{2}  & -2 & \frac{1}{2}  \\
                                 \end{bmatrix} \\
               & = \begin{bmatrix}
                     1 & 0 & 0 \\
                     0 & 1 & 0 \\
                     0 & 0 & 1
                   \end{bmatrix}                                 \\
    \end{align*}
  }

}

\chapter{Determinants}

\section{Introduction}

To extend the concept of the determinant to  $n \times n$ matrices we must use this recursive definition:

\dfn{The Determinant of a $n\times n$ matrix}{
  For $n \geq 2$, the determinant of an $n \times n$ matrix $A = \left[ a_{ij} \right] $ is the sum of terms of the form
  $\pm a_{1j}$ det$A_{1j}$, with plus and minus signs alternating, where the entries  of $a_{11}, a_{12}, \ldots,
    a_{1n}$ are form the first row of $A$, i.e.:
  \begin{align*}
    \det A & = a_{11} \text{det} A_{11} - a_{12} \text{det} A_{12} + \ldots + (-1)^{1+n} a_{1n} \text{det} A_{1n}
    \\
           & = \displaystyle\sum_{j=1}^{n} \left( -1 \right)^{1 + j} a_{1j} \det A_{1j}                           \\
  \end{align*}
}

Where $A_{1j}$ refers to the matrix obtained by crossing out the first row and the $j$th column of $A$, which if $A$ is
a $3\times 3$ matrix would result in a $2\times 2$ one allowing us to find the determinant of $A_{1j}$ using \ref{thg:det}

\ex{}{
  \qs{}{
    Compute the determinant of
    \[
      A = \begin{bmatrix}
        1 & 5  & 0  \\
        2 & 4  & -1 \\
        0 & -2 & 0
      \end{bmatrix}
    \]
  }

  \sol{
    \begin{align*}
      \text{det } A & = \displaystyle\sum_{j=1}^{n} \left( -1 \right) ^{1+j} a_{1j} \det A_{1j} \\
                    & = a_{11} \det A_{11} - a_{12} \det A_{12} + a_{13} \det A_{13}            \\
                    & =  1 \begin{vmatrix} 4 & 1 \\ 2 & 0 \end{vmatrix} - 5 \begin{vmatrix} 2
                                                                               & -1 \\  0 &
                                                                              0\end{vmatrix} +
      0
      \begin{vmatrix}
        2 & 4 \\ 0 & -2\end{vmatrix}                                                              \\
                    & = 1 \left( 0 - 2 \right) - 5 \left( 0 \right) + 0 \left( -4 \right)       \\
                    & = -2                                                                      \\
    \end{align*}
  }
}

The definition of $\det A$ can also be written in the form of a \textit{cofactor expansion}, Given $A = \left[ a_{ij}
    \right] $, the $ \left( i, j \right)\text{-cofactor} $ of $A$ is the number $C_{ij}$ defined by:
\[
  C_{ij} = \left( -1 \right)^{i+j} \det A_{ij}
\]
Allowing us to express $\det A$ as:
\begin{align*}
  \det A & = \displaystyle\sum_{j=1}^{n} a_{1j} C_{1j} \\
         & = a_{11} C_{11} + \ldots + a_{1n} C_{1n}    \\
\end{align*}
This is termed as the \textit{cofactor expansion of the determinant along the first row} of $A$.

\thm{Cofactor Expansion}{
  The determinant of any $n\times n$ matrix $A$ can be computed by a cofactor expansion across any row or down any column.
  The expansion across the $i$th row is:
  \begin{align*}
    \det A & = \displaystyle\sum_{j=1}^{n} a_{ij} C_{ij}              \\
           & = a_{i1} C_{i1} + a_{i2} C_{i2} + \ldots + a_{in} C_{in} \\
  \end{align*}
  And the expansion down the $j$th column is:
  \begin{align*}
    \det A & = \displaystyle\sum_{i=1}^{n} a_{ij} C_{ij}              \\
           & = a_{1j} C_{1j} + a_{2j} C_{2j} + \ldots + a_{nj} C_{nj} \\
  \end{align*}
}

\ex{}{
  \qs{}{
    Use a cofactor expansion across the third row to compute the determinant of $A$, where
    \[
      A = \begin{bmatrix} 1 & 5 & 0 \\ 2 & 4 & -1 \\ 0 & -2 & 0 \end{bmatrix}
    \]
  }

  \sol{
    \begin{align*}
      \det A & = \displaystyle\sum_{j=1}^{n} a_{3j} C_{3j}                                                              \\
             & = 0  \begin{vmatrix} 5 & 0 \\ 4 & -1 \end{vmatrix} + 2 \begin{vmatrix} 1 & 0 \\ 2 & -1 \end{vmatrix} + 0
      \begin{vmatrix} 1 & 5 \\ 2 & 4 \end{vmatrix}                                                                      \\
             & = 0 + 2 \left( -1 \right) + 0                                                                            \\
             & = -2                                                                                                     \\
    \end{align*}
  }
}

In the case where we are computing the determinant of a matrix with great dimension, we take the cofactor across the row
or column with the most zeros.

\ex{}{
  \qs{}{
    Compute $\det A$, where
    \[
      A = \begin{bmatrix}
        3 & - 7 & 8  & 9  & -6 \\
        0 & 2   & -5 & 7  & 3  \\
        0 & 0   & 1  & 5  & 0  \\
        0 & 0   & 2  & 4  & -1 \\
        0 & 0   & 0  & -2 & 0
      \end{bmatrix}
    \]
  }

  \sol{
    We take the cofactor expansion down the first column of $A$.

    \begin{align*}
      \det A & = \displaystyle\sum_{i=1}^{n} a_{i1} C_{i3}                                                                \\
             & = a_{11} C_{11} + a_{21} C_{21} + a_{31} C_{31} + a_{41} C_{41} + a_{51} C_{51}                            \\
             & = 3 \begin{vmatrix} 2 & -5 & 7 & 3 \\ 0 & 1 & 5 & 0 \\ 0 & 2 & 4 & -1 \\ 0 & 0 & -2 & 0 \end{vmatrix} + 0
      C_{21} + 0 C_{31} + 0 C_{41} + 0 C_{51}                                                                             \\
             & \text{We disregard the zero terms}                                                                         \\
             & = 3 \begin{vmatrix} 2 & -5 & 7 & 3 \\ 0 & 1 & 5 & 0 \\ 0 & 2 & 4 & -1 \\ 0 & 0 & -2 & 0 \end{vmatrix}      \\
             & \text{Next we perform a cofactor expansion down the 1st column of our determinant}                         \\
             & = 3 \left(
      \displaystyle\sum_{i=1}^{n} a_{i1} C_{i1}
      \right)                                                                                                             \\
             & = 3 \left(
      a_{11} C_{11} + a_{21} C_{21} + a_{31} C_{31} + a_{41} C_{41}
      \right)                                                                                                             \\
             & = 3 \left( 2 \begin{vmatrix} 1 & 5 & 0 \\ 2 & 4 & -1 \\ 0 & -2 & 0 \end{vmatrix} - 0 C_{21} + 0 C_{31} - 0
      C_{41}\right)                                                                                                       \\
             & = 3 \times 2 \begin{vmatrix} 1 & 5 & 0 \\ 2 & 4 & -1 \\ 0 & -2 & 0 \end{vmatrix}                           \\
             & = 3 \times 2 \left(
      \displaystyle\sum_{j=1}^{n} a_{3j} C_{3j}
      \right)                                                                                                             \\
             & = 3 \times 2 \left( a_{31} C_{31} + a_{32} C_{32} + a_{33} C_{33} \right)                                  \\
             & = 3 \times 2 \left( 0 C_{31} + 2 \begin{vmatrix} 1 & 0 \\ 2 & -1 \end{vmatrix} + 0 C_{33}  \right)         \\
             & = 3 \times 2 \times 2 \left( -1 \right)                                                                    \\
             & = -12                                                                                                      \\
    \end{align*}
  }
}

\thm{}{
  If $A$ is a triangular matrix, then $\det A$ is the product of the entries on the main diagonal of $A$.
}

\subsection{Exercises}

\qs{}{
  Compute
  \[
    \begin{vmatrix}
      5  & -7 & 2 & 2  \\
      0  & 3  & 0 & -4 \\
      -5 & -8 & 0 & 3  \\
      0  & 5  & 0 & -6
    \end{vmatrix}
  \]
}

\sol{
  \begin{align*}
    \det A & = \displaystyle\sum_{j=1}^{n} a_{4j} C_{4j}                                                                                                           \\
           & = a_{41} C_{41} + a_{42} C_{42} + a_{43} C_{43} + a_{44} C_{44}                                                                                       \\
           & = 0 C_{41} - 5 \begin{vmatrix} 5 & 2 & 2\\ 0 & 0 & -4 \\ -5 & 0 & 3  \end{vmatrix} + 0 C_{43} + 6
    \begin{vmatrix} 5 & -7 & 2 \\ 0& 3 & 0 \\ -5 & -8 & 0 \end{vmatrix}                                                                                            \\
           & = 5 \left( \displaystyle\sum_{j=1}^{n} a_{2j} C_{2j} \right) + 6 \left( \displaystyle\sum_{j=1}^{n} a_{2j} C_{2j} \right)                             \\
           & = 5 \left( 0 C_{21} - 0 C_{22} -4 \begin{vmatrix} 5 & 2 \\ -5 & 0 \end{vmatrix}  \right) + 6 \left( \displaystyle\sum_{j=1}^{n} a_{2j} C_{2j} \right) \\
           & = 5 \left( 0 + 40 \right)  + 6 \left( 0 C_{21} - 3 \begin{vmatrix} 5 & 2 \\ -5 & 0 \end{vmatrix} + 0 C_{23}  \right)                                  \\
           & = 200 + 6 \left( -3 \times 10 \right)                                                                                                                 \\
           & = 200 - 180                                                                                                                                           \\
           & = 20                                                                                                                                                  \\
  \end{align*}
}

\section{Properties of Determinants}

\thm{Row Operations}{
  Let $A$ be a square matrix, Then:
  \begin{enumerate}
    \item If a multiple of one row $A$ is added to another row to produce a matrix $B$, then $\det B = \det A$
    \item If two rows of $A$ are interchanged to produce $B$, then $\det B = - \det A$
    \item If one row of $A$ is multiple by $k$ to produce $B$, then $\det B = k\cdot \det A$
  \end{enumerate}
}

\ex{}{
  \qs{}{
    Compute $\det A$, where $A = \begin{bmatrix}
        1  & - 4 & 2  \\
        -2 & 8   & -9 \\
        -1 & 7   & 0  \\
      \end{bmatrix} $
  }

  \sol{
    We can reduce the matrix $A$ to reduced row echelon form then use the fact that the determinant of a triangular matrix
    is the product of main diagonal entries.

    \begin{align*}
      \det A & = \begin{vmatrix}
                   1  & - 4 & 2  \\
                   -2 & 8   & -9 \\
                   -1 & 7   & 0  \\
                 \end{vmatrix}      \\
             & = \begin{vmatrix}
                   1  & -4 & 2  \\
                   0  & 0  & -5 \\
                   -1 & 7  & 0
                 \end{vmatrix}      \\
             & = \begin{vmatrix}
                   1 & -4 & 2  \\
                   0 & 0  & -5 \\
                   0 & 3  & 2
                 \end{vmatrix}      \\
             & = \begin{vmatrix}
                   1 & -4 & 2  \\
                   0 & 3  & 2  \\
                   0 & 0  & -5
                 \end{vmatrix}      \\
             & = 1 \times 3 \times -5 \\
             & = -15                  \\
    \end{align*}
  }
}




\chapter{Exercises}

\qs{}{
  Compute the product $A B$ using:
  \begin{itemize}
    \item The definition where $A b_1, A b_2$ are computed separately.
    \item The row-column rule.
  \end{itemize}
  \[
    A = \begin{bmatrix} -1 & 2 \\ 5 & 4 \\ 2 & -3 \end{bmatrix}, \, B \begin{bmatrix} 3 & -2 \\ -2 & 1 \end{bmatrix}
  \]
}

\sol{
  \begin{enumerate}
    \item
          \begin{align*}
            A b_1 & = \begin{bmatrix} -1 & 2 \\ 5 & 4 \\ 2 & -3 \end{bmatrix} \begin{bmatrix} 3 \\ -2 \end{bmatrix} \\
                  & = \begin{bmatrix} -3 - 4 \\ 15 - 8 \\ 6 + 6 \end{bmatrix}                                       \\
                  & = \begin{bmatrix} -7 \\ 7 \\ 12 \end{bmatrix}                                                   \\
            A b_2 & = \begin{bmatrix} -1 & 2 \\ 5 & 4 \\ 2 & -3 \end{bmatrix} \begin{bmatrix} -2 \\ 1 \end{bmatrix} \\
                  & = \begin{bmatrix} 4 \\ -6 \\ -7 \end{bmatrix}                                                   \\
            \\
            A B   & = \begin{bmatrix} -7 & 4 \\ 7 & -6 \\ 12 & -7 \end{bmatrix}
          \end{align*}
    \item
          \begin{align*}
            A B & = \begin{bmatrix}
                      -1 \times 3 + 2 \times -2 & -1 \times -2 + 2 \times 1 \\
                      5 \times 3 + 4 \times -2  & 5 \times -2 + 4 \times 1  \\
                      2 \times 3 + -3 \times -2 & -2 \times 2 + -3 \times 1
                    \end{bmatrix} \\
                & = \begin{bmatrix}
                      -7 & 4   \\
                      7  & - 6 \\
                      12 & -7
                    \end{bmatrix}                                        \\
          \end{align*}
  \end{enumerate}
}
\qs{}{
  Suppose the last column of $A B$ is entirely zero but $B$ itself has no column of zeros. What can you say
  about the columns of $A$?
}

\sol{
  If the last column of $A B$ is entirely zero, then the last column of $A$ must be a linear combination of the
  columns of $B$. Therefore the columns of $A$ are linearly dependent.
}

\qs{}{
  Find the inverses of the following matrices:
  \begin{enumerate}
    \item \label{itm:inv1}
          \[
            \begin{bmatrix} 8 & 6 \\ 5 & 4  \end{bmatrix}
          \]
    \item
          \[
            \begin{bmatrix} 3 & -4 \\ 7 & -8 \end{bmatrix}
          \]
  \end{enumerate}
}

\sol{
  \begin{enumerate}
    \item
          \begin{align*}
            \det \left( A \right) & = 32 - 30                                                    \\
                                  & = 2                                                          \\
            \\
            A^{-1}                & = \frac{1}{2} \begin{bmatrix} 4 & -6 \\ -5 & 8 \end{bmatrix} \\
                                  & = \begin{bmatrix}
                                        2    & -3 \\
                                        -5/2 & 4
                                      \end{bmatrix}                                             \\
          \end{align*}
    \item
          \begin{align*}
            \det \left( A \right) & = -24 + 28                                                   \\
                                  & = 4                                                          \\
            A^{-1}                & = \frac{1}{4} \begin{bmatrix} -8 & 4 \\ -7 & 3 \end{bmatrix} \\
                                  & = \begin{bmatrix}
                                        -4           & 1           \\
                                        -\frac{7}{4} & \frac{3}{4}
                                      \end{bmatrix}                                 \\
          \end{align*}
  \end{enumerate}
}

\qs{}{
  Use the inverse found in 6 \ref{itm:inv1} to solve the system:
  \begin{align*}
    8x_1 + 6x_2 & = 2  \\
    5x_1 + 4x_2 & = -1
  \end{align*}
}

\sol{
  \begin{align*}
    \mbold{b} = \begin{bmatrix} 2 \\  -1 \end{bmatrix}                \\
    \mbold{x} = A^{-1} \mbold{b}                                      \\
    \\
    \mbold{x} & = \begin{bmatrix}
                    2    & -3 \\
                    -5/2 & 4
                  \end{bmatrix} \begin{bmatrix} 2 \\ -1 \end{bmatrix} \\
              & = \begin{bmatrix}
                    7 \\
                    -9
                  \end{bmatrix}                                      \\
  \end{align*}
}

\qs{}{
  Find the inverse of the following matrix if it exists:
  \[
    \begin{bmatrix}
      1  & -2 & 1  \\
      4  & -7 & 3  \\
      -2 & 6  & -4
    \end{bmatrix}
  \]
}

\sol{
  \begin{align*}
    \begin{bmatrix}
      1  & -2 & 1  \\
      4  & -7 & 3  \\
      -2 & 6  & -4
    \end{bmatrix}
    \\
    4R_1 - R_2  \rightarrow R_2                    \\
    \begin{bmatrix}
      1  & -2 & 1  \\
      0  & -1 & 1  \\
      -2 & 6  & -4 \\
    \end{bmatrix}
    \\
    -2R_1 - R_3  \rightarrow R_3                   \\
    \begin{bmatrix}
      1 & -2 & 1 \\
      0 & -1 & 1 \\
      0 & -2 & 2 \\
    \end{bmatrix}
    \\
    2R_2 - R_3  \rightarrow R_3                    \\
    \begin{bmatrix}
      1 & -2 & 1 \\
      0 & -1 & 1 \\
      0 & 0  & 0 \\
    \end{bmatrix}
    \\
    \det \left( A \right) & = 1 \times -1 \times 0 \\
                          & = 0                    \\
    \therefore \text{ the matrix does not have an inverse}
  \end{align*}
}

\qs{}{
  Suppose the system below is consistent for all possible values of $f$ and $g$. What can you say about the coefficients
  $c$ and $d$? Justify your answer.
  \begin{align*}
    x_1 + 3x_2  & = f \\
    cx_1 + dx_2 & = g \\
  \end{align*}
}

\sol{
  \begin{align*}
    \begin{bmatrix}
      1 & 3 & f \\
      c & d & g
    \end{bmatrix}     \\
    cR_1 - R_2 \to R_2 \\
    \begin{bmatrix}
      1 & 3      & f      \\
      0 & 3c - d & cf - g
    \end{bmatrix}
  \end{align*}
}

\qs{}{
  Let $\mbold{u} = \begin{bmatrix} 2 \\ -1 \end{bmatrix} $ and $\mbold{v} = \begin{bmatrix} 2 \\ 1 \end{bmatrix} $. Show
  that $\begin{bmatrix} h \\ k \end{bmatrix} $ is in $\text{Span}  \{u, v\} $ for all $h$ and $k$.
}

\sol{
  \begin{align*}
    x_1\mbold{u} + x_2 \mbold{v}                 & = \begin{bmatrix} h \\ k \end{bmatrix} \\
    \begin{bmatrix} 2 & 2 \\ -1 & 1\end{bmatrix} & = \begin{bmatrix} h \\ k \end{bmatrix}
  \end{align*}
  Therefore
  \begin{align*}
    \begin{bmatrix}
      2  & 2 & h \\
      -1 & 1 & k
    \end{bmatrix}                \\
    -\frac{1}{2}R_1 - R_2 \to R_2 \\
  \end{align*}
}

\qs{}{
  A steam plant burns two types of coal: anthracite (A) and bituminous (B). For each ton of A burned,
  the plant produces 27.6 million Btu of heat, 3100 grams (g) of sulfur dioxide, and 250 g of
  particulate matter (solid-particle pollutants). For each ton of B burned, the plant produces 30.2
  million Btu, 6400 g of sulfur dioxide, and 360 g of particulate matter.
  \begin{enumerate}
    \item How much heat does the steam plant produce when it burns $x_1$ tons of A and $x_2$ tons of B?
    \item Suppose the output of the steam plant is described by a vector that lists the amounts of
          heat, sulfur dioxide, and particulate matter. Express this output as a linear combination of
          two vectors, assuming that the plant burns $x_1$ tons of A and $x_2$ tons of B.
    \item Over a certain time period, the steam plant produced 162 million Btu of heat, 23,610 g
          of sulfur dioxide, and 1623 g of particulate matter. Determine how many tons of each type
          of coal the steam plant must have burned. Include a vector equation as part of your solution.
  \end{enumerate}
}

\sol{
  \begin{align*}
    27.6x_1 + 30.2x_2 & = \text{Heat}               \\
    3100x_1 + 6400x_2 & = \text{Sulfur Dioxide}     \\
    250x_1 + 360x_2   & = \text{Particulate Matter}
  \end{align*}
  \begin{enumerate}
    \item
          \[
            27.6x_1 + 30.2x_2
          \]
    \item
          \begin{align*}
            27.6x_1 + 30.2x_2             & = H                                            \\
            3100x_1 + 6400x_2             & = SO_2                                         \\
            250x_1 + 360x_2               & = P                                            \\
            \\
            \mbold{u} x_1 + \mbold{v} x_2 & = \begin{bmatrix} H \\ SO_2 \\ P \end{bmatrix} \\
            \text{Where } \mbold{u} = \begin{bmatrix} 27.6 \\ 3100 \\ 250 \end{bmatrix} \text{ and } \mbold{v} = \begin{bmatrix} 30.2 \\ 6400 \\ 360 \end{bmatrix}
          \end{align*}
    \item
          \begin{align*}
            27.6x_1 + 30.2x_2 & = 162                  \\
            3100x_1 + 6400x_2 & = 23610                \\
            250x_1 + 360x_2   & = 1623                 \\
            \\
            \begin{bmatrix}
              27.6 & 30.2 & 162   \\
              3100 & 6400 & 23610 \\
              250  & 360  & 1623  \\
            \end{bmatrix}                        \\
            \frac{7750}{69}R_1 - R_2  \rightarrow R_2  \\
            \begin{bmatrix}
              \frac{138}{5} & \frac{151}{5}      & 162                \\
              0             & \frac{-207550}{69} & \frac{-124530}{23} \\
              250           & 360                & 1623               \\
            \end{bmatrix}
            \\
            \frac{625}{69}R_1 - R_3  \rightarrow R_3   \\
            \begin{bmatrix}
              \frac{138}{5} & \frac{151}{5}      & 162                \\
              0             & \frac{-207550}{69} & \frac{-124530}{23} \\
              0             & \frac{-5965}{69}   & \frac{-3579}{23}   \\
            \end{bmatrix}
            \\
            \frac{112}{3897}R_2 - R_3  \rightarrow R_3 \\
            \begin{bmatrix}
              \frac{138}{5} & \frac{151}{5}      & 162                \\
              0             & \frac{-207550}{69} & \frac{-124530}{23} \\
              0             & 0                  & \frac{0}{1}        \\
            \end{bmatrix}
            \\
            0R_1 - R_3  \rightarrow R_3                \\
            \begin{bmatrix}
              \frac{138}{5} & \frac{151}{5}      & 162                \\
              0             & \frac{-207550}{69} & \frac{-124530}{23} \\
              0             & 0                  & \frac{0}{1}        \\
            \end{bmatrix}
            \\
            0R_2 - R_3  \rightarrow R_3                \\
            \begin{bmatrix}
              \frac{138}{5} & \frac{151}{5}      & 162                \\
              0             & \frac{-207550}{69} & \frac{-124530}{23} \\
              0             & 0                  & \frac{0}{1}        \\
            \end{bmatrix}
            \\
            \frac{-98}{9761}R_2 - R_1  \rightarrow R_1 \\
            \begin{bmatrix}
              \frac{-138}{5} & 0                  & \frac{-2691}{25}   \\
              0              & \frac{-207550}{69} & \frac{-124530}{23} \\
              0              & 0                  & \frac{0}{1}        \\
            \end{bmatrix}
            \\
            0R_2 - R_1  \rightarrow R_1                \\
            \begin{bmatrix}
              \frac{138}{5} & 0                  & \frac{2691}{25}    \\
              0             & \frac{-207550}{69} & \frac{-124530}{23} \\
              0             & 0                  & \frac{0}{1}        \\
            \end{bmatrix}
            \\
            0R_2 - R_1  \rightarrow R_1                \\
            \frac{5}{138}R_1 \to R_1                   \\
            \frac{-1}{3008}R_2 \to R_2                 \\
            \begin{bmatrix}
              1 & 0 & \frac{39}{10} \\
              0 & 1 & \frac{9}{5}   \\
              0 & 0 & \frac{0}{1}   \\
            \end{bmatrix}
            \\
            \mbold{x} = \begin{bmatrix} \frac{39}{10} \\ \frac{9}{5} \end{bmatrix}
          \end{align*}

  \end{enumerate}
}

\qs{}{
  Describe and compare the solution sets of $x_1-3x_2+5x_3 = 0$ and $x_1-3x_2+5x_3 = 4$.
}

\sol{
  \begin{align*}
    \begin{bmatrix}
      1 & -3 & 5 & 0 \\
      0 & 0  & 0 & 0 \\
      0 & 0  & 0 & 0 \\
    \end{bmatrix}       \\
    x_1 -3x_2 + 5x_3 = 0 \\
    x_2 = x_2            \\
    x_3 = x_3            \\
    x_1 = 3x_2 - 5x_3    \\
    \\
    \mbold{x} = \begin{bmatrix} 3 \\ 1 \\ 0 \end{bmatrix} x_2 + \begin{bmatrix} -5 \\ 0 \\ 1 \end{bmatrix} x_3
  \end{align*}
}


\end{document}
